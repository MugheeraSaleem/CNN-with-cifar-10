# -*- coding: utf-8 -*-
"""Cifar_10 using CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IJ7HAG0vn-Yt-CJnCkeQ20tz623iR8jC

**Imports**
"""

# -*- coding: utf-8 -*-
"""
Created on Mon Nov 21 23:25:17 2022

@author: haier
"""

import tensorflow as tf
from matplotlib import pyplot
from keras.datasets import cifar10
import sys
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""**Loading** **Dataset** **and** **Pre_processing**"""

def load_data():
    # load dataset
    (trainX, trainY), (testX, testY) = cifar10.load_data()
    # summarize loaded dataset
    
    (valX , valY) = (trainX[:10000], trainY[:10000])
    
    (trainX, trainY) = (trainX[10000:], trainY[10000:])   
    
    print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))
    print('Test: X=%s, y=%s' % (testX.shape, testY.shape))
    print('Validation: X=%s, y=%s' % (valX.shape, valY.shape))
    # plot first few images
    for i in range(9):
    	# define subplot
    	pyplot.subplot(330 + 1 + i)
    	# plot raw pixel data
    	pyplot.imshow(trainX[i])
    # show the figure
    pyplot.show()
    
    # this is only done if loss is taken as categorical_crossentropy
    trainY = tf.keras.utils.to_categorical(trainY)
    testY = tf.keras.utils.to_categorical(testY)
    valY = tf.keras.utils.to_categorical(valY)
    
    testX= testX/255.0

    return trainX,trainY,valX,valY,testX,testY
    
trainX,trainY,valX,valY,testX,testY = load_data()

"""**Data Generator for Training and Validation**"""

def train_val_generator(trainX,trainY,valX,valY,testX,testY):
    
    train_datagen = ImageDataGenerator( 
                                      rescale = 1./255.0,
                                      width_shift_range=0.1, 
                                      height_shift_range=0.1, 
                                      horizontal_flip=True
                                     )
    
    train_generator = train_datagen.flow(x=trainX, y=trainY, batch_size=200)
    
    val_datagen = ImageDataGenerator(rescale=1/255.0)
    val_generator = val_datagen.flow(x=valX,y=valY,batch_size=100)
    
    #test_datagen = ImageDataGenerator(rescale=1/255.0)
    #test_generator = test_datagen.flow(x=testX,y=testY,batch_size=100)
    
    return train_generator,val_generator#,test_generator

train_generator,val_generator = train_val_generator(trainX,trainY,valX,valY,testX,testY)

"""**Model Architecture**"""

def create_model():      
  # Define the model
  model = tf.keras.models.Sequential([   
  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)),
	tf.keras.layers.BatchNormalization(),
	tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
	tf.keras.layers.BatchNormalization(),
	tf.keras.layers.MaxPooling2D((2, 2)),
	tf.keras.layers.Dropout(0.2),
	tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
	tf.keras.layers.BatchNormalization(),
	tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
	tf.keras.layers.BatchNormalization(),
	tf.keras.layers.MaxPooling2D((2, 2)),
	tf.keras.layers.Dropout(0.3),
	tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
	tf.keras.layers.BatchNormalization(),
	tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),
	tf.keras.layers.BatchNormalization(),
	tf.keras.layers.MaxPooling2D((2, 2)),
	tf.keras.layers.Dropout(0.4),
	tf.keras.layers.Flatten(),
	tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),
	tf.keras.layers.BatchNormalization(),
	tf.keras.layers.Dropout(0.2),
	tf.keras.layers.Dense(10, activation='softmax')    
    ])

  model.compile(optimizer = 'Adam',
                loss = 'categorical_crossentropy',
                metrics=['accuracy'])
  
  return model
model = create_model()

"""**Plotting Helper Function**"""

def summarize_diagnostics(history):
	# plot loss
	pyplot.subplot(211)
	pyplot.title('Cross Entropy Loss')
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')
	# save plot to file
	filename = sys.argv[0].split('/')[-1]
	pyplot.savefig(filename + '_plot.png')
	pyplot.close()

history = model.fit(train_generator,epochs=60,validation_data= val_generator)

"""**Evaluating Model**"""

loss, acc = model.evaluate(testX, testY, verbose=0)
print('> %.3f' % (acc * 100.0))
print('> %.3f' %loss)
# learning curves
summarize_diagnostics(history)
model.metrics_names